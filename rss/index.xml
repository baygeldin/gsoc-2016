<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GSoC 2016</title>
    <link>http://baygeldin.name/gsoc-2016</link>
    <description>Web GDB frontend project with Mozilla.</description>
    <atom:link href="hello-world/feed.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>Shaping</title>
        <description><![CDATA[<p>In the previous post I told about initial scaffolding of the GUI and this week I&#39;ve been working on making the project architecture more solid, adding new features, fixing bugs. Unfortunately, I somehow managed to catch a cold in the high summer and it significally slowed me down. But anyway, I&#39;ve run the demo application, now it looks like this:</p>
<p><img src="http://baygeldin.name/gsoc-2016/assets/images/demo.jpg" alt="Snapshot"></p>
<p>In this post I&#39;d like to talk about a lot of different things, but I&#39;ll try to avoid boring details in order to not make this post longer than it already is. So, let&#39;s start.</p>
<h2>UX</h2><p>First, I&#39;d like to outline the main functionality of the app and how it works (how I see it should work). Obviously, it should support file manager, multithreading, callstacks, variables, breakpoints, but the details of user interaction with all of this are not obvious at all, so here&#39;s how I see it:</p>
<ul>
<li>When user clicks on a thread, the current file for this thread is opened in the main area (the editor) and it focuses on the current line for this thread (i.e. the editor is focused on a current frame). The same happens when we click on a callstack level or a breakpoint and when the current thread is stopped for some reason (e.g. after stepping through the code). I haven&#39;t added this functionality to the ace editor yet, but everything else is working (everytime the editor should focus on the frame, the message is sent to console log). This feature is kind of unusual for Redux/React app since it doesn&#39;t ideally fit to the concept of &quot;function of data&quot; and using refs here is also not a good option since it complicates the code. So I created an additional field in the store for the focused frame. I pass this object as props to the editor and when it changes, the editor gets focused on the frame. I think that this is mostly reasonable approach.</li>
<li>Application state is always associated with some thread and only related context, callstack and breakpoints are printed. Also everytime user sets a breakpoint it&#39;s applied only to the current thread. But setting and removing breakpoints that are applied to all threads is also necessary, so I decided that when user holds <code>Ctrl</code> and clicks on the gutter to set a breakpoint, breakpoint is set to all threads. Good news is that GDB is capable of doing all these things even for multiple targets that share the same code, however there&#39;re some bearable specifics.</li>
<li>At the start no thread is selected and the debugging is not started yet. However, we can open files and set breakpoints that will be applied to all threads. Instead of &quot;continue&quot;  and &quot;pause&quot; buttons we see &quot;run&quot; button.  The first added thread gets selected automatically.</li>
<li>Threads are grouped by their belonging to inferiors, but all of them are equal. Every thread has its status (stopped or running), every thread can be debugged separately. Also, when it&#39;s stuck (e.g. infinite loop) we can interrupt (pause) it and then continue, if we want.</li>
<li>Current line (of the current thread frame) is highlighted in the editor.</li>
<li>The sources are fetched only at the moment when you open them in the editor.</li>
</ul>
<p>Almost everything here is ready (through the console or GUI), however some bugs are possible.</p>
<h2>Component design</h2><p>Right now ReactGDB has this interface:</p>
<ul>
<li>A process with stdin, stdout and stderr Node.js streams.</li>
<li>Source provider with two fields: &quot;fetch&quot; which is a function that accepts a fullpath to a file and returns a Promise that resolves with the source of this file, and &quot;basePath&quot; string that helps to distinguish between project and system files.</li>
<li>Inferior provider is an EventEmitter with &quot;fork&quot; event that accepts callback and pass pid as the first argument to it. I really don&#39;t know how such provider should be implemented, but I also know that there&#39;s no way that ReactGDB can do it on its own (crossplatform). But with such provider working with multiple targets become really easy.</li>
</ul>
<p>There&#39;s not much sense in changing these props in the runtime, so I decided to warn user when he changes the props and re-render whole app with new props. By the way, even if server rendering also makes no sense for ReactGDB, I was interested in how to create reusable components that at least not breaking anything when you try to render on the server. And it surprised me that I couldn&#39;t find any best practices and rules for it. After a little investigation I understood that the rule of thumb is actually pretty simple. Put all of asynchronous stuff and things that can trigger browser API to <code>componentDidMount</code> method. It&#39;s easy to follow and this is what I do.</p>
<h2>Build system</h2><p>I believe that properly adjusted build system is the most important part of the project. No one needs a project that they can&#39;t build :) And well, build system that is fragile and slow is killing all motivation sometimes. So I spent some time optimizing speed and convenience of my build system. I&#39;ll spare you off boring details about optimizing speed (HappyPack, DLLPlugin, CommonsChunkPlugin, etc.), but I&#39;d like to note that the best performance I achieved with just using multiple configurations. However, this config was very bloated and hardly maintainable, so I switched to a more concise one and made use of webpack-dev-server in order to serve bundles from memory and enable auto-refreshing. I&#39;m fine with the current performance.  </p>
<p>Also, in the last post I said that CSS Modules are hard to customize and thus using single CSS file is more appropriate. I was wrong about theming, <a href="https://github.com/css-modules/css-modules/blob/master/docs/theming.md">it&#39;s actually pretty easy</a> to do it even without webpack (however, webpack makes it super simple). But it wouldn&#39;t have been enough for me to switch over to CSS Modules. The thing I love about them is about keeping related things together. The decision to treat all static assets as modules is actually a killer feature of webpack even if it can seem a little strange from the first look. Keeping domain specific things together is very convinient and it also makes build system extremly flexible. I have two webpack configurations now, one for production and one for development. Production build makes a CommonJS module (without bundling dependencies, of course) and put it with its static assets to a <code>lib</code> folder. Development build makes two chunks: vendor chunk for all third-party dependencies and bundle chunk for gdb-js, react-gdb and example app (such separation makes build x5 times faster). It&#39;s notable that using webpack for all the things made it unnecessary to use <code>npm link</code>. However, development build depends on a specific version of <code>docker-exec-websocket-server</code> which is different from the npm version. But I&#39;ve already <a href="https://github.com/taskcluster/docker-exec-websocket-server/pull/7">sent a PR</a> and once new version is published it will build just fine.</p>
<h2>Structure</h2><p>I feel quite confident about the current project structure now and I think that it&#39;s unlikely that it will change significantly in the future. Main entry of application is <code>index.jsx</code>. It initializes store, actions, selector and gdb-js instance. <code>actions.js</code> exports a function that accepts stores dispatch method and returns binded to store actions. <code>store.js</code> exports a function that creates store with defined middlewares and reducers. <code>selector.js</code> exports a function that creates memoized selector. Well, initially I was passing bare application state to the upper component and calculating derived data (which I then pass to other components) there. But it was obviously not a good solution since it required too much evaluations on every render. So I decided to optimize it and stumbled upon <code>reselect</code> library that is able to memoize such calculations and highly optimize the application. I couldn&#39;t find any best practices on whether selectors should be in one place or we should split them to different modules, so I decided to place them in one file that works like a one way ModelView for application state. So, now I have one smart component which is listening to the store and   maps state to data that presentational components can consume easily. In the <code>components</code> folder all components are presentational. It turned out that this approach works pretty good. Maybe for big projects it won&#39;t work, but if the project is big, then it should be looking to something other than Redux I guess. However, I noticed that it&#39;s relatively easy to write selectors that make uneccessary recalculations. To avoid it I defined a couple of rules that should be followed when writing selectors: keep selectors small; less dependencies is better (e.g. two is perfect); be careful when creating new objects in a selector. Luckily, when all selectors are in a single file, these rules are very easy to follow.</p>
<h2>Debug</h2><p>I use <code>debug</code> npm package to see logs from both gdb-js and react-gdb. Logging functions for react-gdb I store in the  <code>debug.js</code> file. For all of the sources (react-gdb, gdb-js and example application) I use full source-map generation (despite this, builds are still fast). Source maps also work for stacktraces (it&#39;s necessary when error is throwed inside the promise).  I use ReduxDevTools and also I injected binded to store actions to the global object so that I can use and debug them without creating GUI first. Also I try to document PropTypes very thoroughly. It&#39;s a little verbose so that I even decided to put common PropTypes to a <code>/components/common.js</code> file, but I found out that it can really help to catch unobvious bugs.</p>
<h2>Planes</h2><ul>
<li>In the code of react-gdb there are a lot of <code>parseInt</code> here and there. It&#39;s because of gdb-js not handling conversation of strings to numbers itself. So what I&#39;d like to do is defining what objects gdb-js returns from its methods, documenting it and releasing a new version on npm (I&#39;ve already fixed a bunch of bugs, so it&#39;s time for a new release anyway).</li>
<li>I need to create a new multithreaded example in the <code>gdb-examples</code> repo that has multiple files (in order to test the tree view for sources).</li>
<li>Besides, I haven&#39;t added needed functionality to <code>ace.js</code> yet, so this is what I need to do next.</li>
<li>When I get confident that implemented functionality is working well and have almost no bugs, I will split up presentational components, add styles, then I&#39;ll write tests, document the code and write documentation.</li>
</ul>
<h2>P.S.</h2><p>Seems like I&#39;ve been too optimistic when I was writing timeline in the project proposal, heh :D I didn&#39;t count curveballs and back then I was imagining the project a little bit differently. But I still believe that I can drive the project into a very solid state until GSoC ends.</p>
]]></description>
        <pubDate>Wed Jul 27 2016 00:00:00 GMT+0300 (MSK)</pubDate>
        <link>http://baygeldin.name/gsoc-2016/shaping</link>
        <guid isPermaLink="true">http://baygeldin.name/gsoc-2016/shaping</guid>
      </item>
    
    
      <item>
        <title>GUI</title>
        <description><![CDATA[<p>Seems like quite some time have passed since the last post. That&#39;s because in the end of the last month I was busy with passing the last exams. And this month I&#39;ve finally started to do the GUI. First off, I thought out the structure of the application, decided which tools to use and which not by weighting all the pros and cons, and wrote some code. Unfortunately, I haven&#39;t managed to run the working demo yet, but I&#39;m close to this. In this post I&#39;d like to talk about three things: structure of React/Redux app, managing CSS styles in the component and the choice of code editor. So, let&#39;s start.</p>
<h2>React/Redux</h2><p>Although I&#39;m familiar with both React and Redux and done some stuff with them, but to be honest, I&#39;ve never done <em>complex</em> web applications with this stack and that&#39;s why sometimes I&#39;m not sure what&#39;s the right way to do some things. For example, I&#39;ve encountered a problem that somehow I can&#39;t build the UI gradually, step-by-step. Just to start writing code I needed to fully outline the application structure, its logic and data flow, because it seemed to me that every change to it later will lead to significant code rewriting. I checked out documentation and found out that it&#39;s actually not far from being truth. It&#39;s said there that designing state shape should actually be done &quot;before writing any code&quot;. And for complex applications it can be really tricky. So, I guess it&#39;s more like a consequence of Redux approach, luckily it should be done only once. Generally, I thought out the application logic, then based on it I created all actions needed for this, then I designed some middlewares to deal with asynchronous actions, then I wrote reducers to handle these actions and only after that I created some views (components). By the way, I made use of <code>immutable.js</code> library, because it&#39;s perfectly match Redux and because it&#39;s just super cool. Basically, the core logic of GUI is ready and now I need to make it running and tighten it up.</p>
<h2>Managing CSS</h2><p>In the proposal to this project I said that a single CSS file will be enough, but when I started working on the GUI I decided to put a little more thought into this (probably because of curiosity) and in the end I reverted to the point I started from :) But now I have some good arguments. Let&#39;s start with the obvious problems that CSS have: bad encapsulation and terrible reusability. And these things matter in the big projects. Once I was working in the project with huge codebase where even BEM was absent. I needed to take one piece of a page and just paste it to another. This type of task should take merely 5 minutes to finish. But it costed me half a day. That&#39;s why encapsulation matters. Moreover, using third-party components can also be entangling due to these problems. There&#39;re several options to choose from when you want to deal with them: BEM, CSS Modules, inline styles, Web Components. I considered all of them from the point of writing CSS for a reusable React component. What I tried to achieve is to make component easily cusomizable (through CSS overriding, because CSS is a perfect DSL for this kind of stuff) and avoid collisions with other CSS styles. And since customization was one of the main goals I ditched inline styles immediately (even though they are promoted heavily in the React community). BEM has a lot of boilerplate but it&#39;s simple and it works. The point is, it&#39;s needed only in big projects with a lot of components (and I have only one). CSS Modules/ICSS is a very interesting approach, but it based on adding random hashes to CSS classes which makes customization very hard. It cures symptoms, not the problem itself. So, I decided that the most natural approach is just give the user a simple, plain, good old CSS file to include into his page and override it. To avoid collisions we can use prefixes (I use PostCSS to accomplish this). Of course it doesn&#39;t solve the problem with encapsulation. But the most important thing that I&#39;ve understood from all of this is — I don&#39;t need to solve it! It&#39;s user who should think of this, not the component distributer. When you&#39;re developing a component it&#39;s perfectly fine to just have a main file for styles (or a couple of them). I&#39;d rather say it should be done this way. But how the user is supposed to solve the problem with encapsulation by himself? The answer is Shadow DOM. And for the reusability problem (which is more general) it&#39;s Web Components. For a long time I was feeling very sceptic about Web Components standard, it seemed overcomplicated to me. But I was wrong. In fact, they solve all of the stated problems without compromising the customization and without changing the way we think about CSS. Also, I thought of Web Components as the competitor of React. Wrong again! They solve completely different problems. Web Components help to reuse parts of application across different projects without breaking the styles and it&#39;s their main goal. React on its side helps to build application architecture based on the components model and represent it as the function of data. And they can be easily used together! We can build Web Component using React. We can use Web Components in our React application. That&#39;s the point. Of course the browser support of Web Components is not good enough (yet), but I find the idea behind them to be very neat. Well, seems like I dived into this a bit much, but I&#39;m glad that now a have a good understanding.</p>
<h2>Editor</h2><p>Initially I decided to use Prism with a bunch of plugins for syntax highlighting. But then <strong>@jonasfj</strong> suggested to use full-fledged code editor instead (like Ace or Codemirror). And it was a great idea! :) I decided to use Ace, because it&#39;s more popular and have all of the needed features: the ability to set breakpoints, readonly mode, specific line highlighting (markers). It&#39;d be nice if it also could focus (i.e. center the viewport) on the specific line, &#39;cause I left a place for this functionality in the React application. By the way, I found a ready React component for this editor. Unfortunately, it doesn&#39;t support <code>guttermousedown</code> event which I need. I think I&#39;ll fork it, add this functionality, and install it directly from my repo with npm (I don&#39;t think that PR will be merged as soon as I send it). </p>
<h2>Planes</h2><ul>
<li>Embed Ace editor</li>
<li>Launch the demo</li>
<li>Finish and style the components</li>
<li>Create the tree view for the sources (instead of a plain list)</li>
<li>Add support for multiple targets</li>
<li>Optimize some parts of code where it makes sense</li>
</ul>
<h2>P.S.</h2><p>Generally, everything is proceeding according to plan. I guess that the next post I will write when I finish the component and run the demo. Although, reasonable UX for multiple target might have some time.</p>
]]></description>
        <pubDate>Sun Jul 10 2016 00:00:00 GMT+0300 (MSK)</pubDate>
        <link>http://baygeldin.name/gsoc-2016/gui</link>
        <guid isPermaLink="true">http://baygeldin.name/gsoc-2016/gui</guid>
      </item>
    
    
      <item>
        <title>Milestone</title>
        <description><![CDATA[<p>Weekly reports are slowly turning into fortnightly reports, heh. But despite this I&#39;m satisfied with the progress. During this time I managed to finish <code>gdb-js</code>, write documentation for it, publish it on npm and set up CI. Also, I fixed the <code>ws-streamify</code> and puzzled out the debugging of multithreaded and multi-process&#39;ed targets in GDB and added the corresponding examples to <code>gdb-examples</code> repo. But what&#39;s more important — I&#39;ve finally acquired a good understanding of how the project should be implemented. And in the meantime I&#39;ve passed another exam :D But let&#39;s see it in a little more detail.</p>
<h2>Multithreading</h2><p>Honestly, I hate multithreading :D Except maybe its application to pure functional languages. But for everything else it just sounds scary to me. Deadlocks, unobvious control flow... That&#39;s why I like event-loop. And that&#39;s why I deliberately avoided this topic while I was writing <code>gdb-js</code>. But it couldn&#39;t be postponed forever, so I created a simple yet handy example of multithreaded program for <code>gdb-examples</code> repo: multiple ticket-sellers sell tickets simultanously until there&#39;s no tickets remain. And while playing with it in GDB I understood that <code>non-stop</code> and <code>target-async</code> modes are must have in a GDB frontend. So i included them in <code>gdb-js</code> and then added <code>thread</code> argument to all of the methods where it makes sense. That&#39;s it.</p>
<h2>Multiple targets</h2><p>First off, I read <a href="http://blog.chromium.org/2008/09/multi-process-architecture.html">how it works in Chromium</a> and then <a href="https://blog.mozilla.org/addons/2016/04/11/the-why-of-electrolysis/">how it&#39;s coming to Firefox</a>. From these articles I understood how important it is to have a multi-process architecture and thus it&#39;s neccessary to have the ability to debug it. However, unlike threads when a process is created it&#39;s not attached to GDB automatically. The exception to this is only systems that support <code>fork</code> and <code>vfork</code>. On other systems (e.g. <a href="https://msdn.microsoft.com/en-us/library/ms682425.aspx">Windows</a>) I believe it should be done manually. But even in this case <a href="https://sourceware.org/gdb/onlinedocs/gdb/Forks.html">it seems that it&#39;s not that straight-forward</a>. So I decided to just add methods for attaching and detaching processes to <code>gdb-js</code> and a method that disables <code>detach-on-fork</code> mode, so that forks will be attached automatically. Also, I&#39;ve created the example of a program with multiple processes (multiple counters) and pushed it to <code>gdb-examples</code> repo.</p>
<h2>Python and CLI commands</h2><p>In previous post I said that MI interface is lacking some commands. But GDB allows to use CLI commands in MI mode with <code>-interpreter-exec console</code>. The only problem with it is getting the results. So I decided to make use of Python and its function <code>gdb.execute(&quot;&lt;CLI command&gt;&quot;, False, True)</code>. In GDB &gt;= 7.3 it has a third argument which when <code>True</code> returns a string with results of CLI command execution. So I wrapped it into an useful command <code>concat</code> which executes given CLI command, adds a given prefix to the results of command execution and prints this in a single MI console record. Also, I&#39;ve created a command <code>info context</code> which takes all variables (globals, static, locals) in the current context and prints a nice JSON. However, getting all (I mean, ALL) globals for the current target is only possible with manually parsing of its symbol table. So I just decided to write one another pegjs parser for the results of <code>info variables</code> command. It all works pretty well. Besides we now have a nice infrastructure to add new functionality to GDB without even bothering the server. However, scripts can be (from my experience) only ~3700 symbols long. Maybe it makes sense to make use of <code>pyminifier</code>. To summarize, this is how I manage the results handling now, it&#39;s an exact copy of the actual flow in the code (I sooo love streams):</p>
<p><img src="http://baygeldin.name/gsoc-2016/assets/images/flow.png" alt="Flow">   </p>
<h2>gdb-js</h2><p><a href="https://travis-ci.org/baygeldin/gdb-js">Here&#39;s</a> Travis CI. <a href="http://npmjs.com/package/gdb-js">Here&#39;s</a> the npm package. <a href="https://baygeldin.github.io/gdb-js">Here&#39;s</a> the documentation. I considered several documentation generators, but then just decided to use JSDoc. Although I also like Docco and its <a href="https://en.wikipedia.org/wiki/Literate_programming">literate programming philosophy</a>. </p>
<h2>react-gdb</h2><p>Finally, the most important part. Thanks to @jonasf I finally realized the core goals that the project is pursuing and how it should be implemented to fit these goals. Back then I thought that <code>react-gdb</code> is just a static site that needs a link to the WebSocket server to work. This made me think that <code>react-gdb</code> is something that has dependency on the server (and its protocol, of course). But in fact, it&#39;s just a React component that can have a much simpler interface (almost the same as <code>gdb-js</code> has). It can accept a child process (e.g. an instance of <code>docker-exec-websocket-server</code>), source provider and (optionally) debug log provider. Source provider can be implemented as a plain function that accecpts a file name and returns the sources of this file (for Firefox, it can be a hg repository provider, for example). This interface will make <code>react-gdb</code> absolutely server-agnostic, agnostic about the location of sources and reusable. So, that&#39;s it. By the way, I&#39;ve also put a lot of thought on how the UI should look like when I add multithreading and multiple targets support to it. I&#39;ve ended up with something similar to NetBeans approach (with the amendment that I want to group threads by a process):</p>
<video controls="controls">
  <source src="http://baygeldin.name/gsoc-2016/assets/other/netbeans-multithreaded-debugging.mp4">
</video>   

<h2>P.S.</h2><ul>
<li>As for <code>ws-streamify</code> it now merges the buffers into one message when it&#39;s possible.</li>
<li>I&#39;ve spent some time on improving my vim workflow with a bunch of useful plugins and now I regret not doing it earlier т_т.</li>
<li>I have an exam on 24th of June. So, I will continue my work on the project after it.</li>
</ul>
]]></description>
        <pubDate>Wed Jun 22 2016 00:00:00 GMT+0300 (MSK)</pubDate>
        <link>http://baygeldin.name/gsoc-2016/milestone</link>
        <guid isPermaLink="true">http://baygeldin.name/gsoc-2016/milestone</guid>
      </item>
    
    
      <item>
        <title>Rethinking</title>
        <description><![CDATA[<p>This week the goal was to write more tests and implement more functionality for a GDB wrapper. However, I&#39;ve faced with some problems that led me to rethinking of library design and changing my plans for project implementation. So, let&#39;s see it step by step.</p>
<h2>Library design</h2><p>Initially I wanted <code>gdb-js</code> to maintain a state because I thought that it&#39;d be more efficient and easier for the end user to consume. But back then I didn&#39;t understand how GDB/MI interface actually works. While reading through documentation I understood that it makes much more sense for a GDB wrapper to provide methods for getting state and events for state changes (e.g. &quot;stopped&quot;, &quot;running&quot;) than a bunch of &quot;update:whatever&quot; events. And it doesn&#39;t make it harder to connect with React application. So the library actually should do well only two things: provide asynchronous methods for GDB commands that return promises that resolve with a JSON object and expose events for state changes. So in the end it should be just a seamless and thin wrapper around GDB/MI parser (which is already written). GDB/MI interfce is perfect for this goal because on every command it returns only one line with a result. However, not everything in the garden is rosy... Some commands that I need GDB/MI does not support. For example, the <code>-symbol-list-variables</code> command which I need for getting globals is absent even if it&#39;s written in the documentation. The correspondent GDB command for it is <code>info variables</code> but using it is far from comfortable since it doesn&#39;t return only one line with a result. However, seems like it&#39;s a synchronous operation and every line between our command and <code>^done</code> line is the result of this operation. So, I believe I should just parse them somehow. At this stage I just made some refactoring on the library and disabled all previous tests.  </p>
<p>The next problem with GDB/MI is that it&#39;s impossible to distinguish between target program output and GDB/MI output even if it&#39;s said that all target program output will be prefixed with @. Sounds good, but it&#39;s not true (see the <a href="https://sourceware.org/bugzilla/show_bug.cgi?id=8759">#8759 bug</a>). So I went a simple way and decided to return every line that a wrapper can&#39;t parse as a target program output. However, for this specific project (i.e. <code>react-gdb</code>) I believe that it makes more sense to require server to run GDB with <code>--tty=/what/ever</code> and leave it to user how to interact with this tty.  </p>
<p>In general I want to finish GDB wrapper during the next week and start doing UI. But before doing UI I need to understand how the interaction with a server should work and it&#39;s another matter...</p>
<h2>Server interaction</h2><p>Again, initially the <code>docker-exec-websocket-server</code> was suggested to use with <code>react-gdb</code>. Although it does a good job on exposing process streams from docker running on the server it&#39;s not enough for a debugger frontend. Debugger itself should also be a file explorer and (maybe) something else. It needs his own protocol. I considered three options:</p>
<ol>
<li>Still use <code>docker-exec-websocket-server</code> protocol, for everything else send HTTP requests</li>
<li>Modify <code>docker-exec-websocket-server</code> by adding new message types</li>
<li>Dirty hacks with remote procedures calling </li>
</ol>
<p>The first option seems like an overhead and it will be hard to document such protocol as well as to implement it. The third option has a whole bunch of different pitfalls so I don&#39;t even want to think of it. So I decided to go with the second option. While reading again through the sources of <code>docker-exec-websocket-server</code> I&#39;ve noticed that the only tricky part of it is back-pressure implementation (it also occupies the largest part of the code). So I thought, why not decouple it so that it would be easy to implement the new protocol with back-pressure? As a result I made the <code>ws-streamify</code> package.</p>
<h2><a href="https://github.com/baygeldin/ws-streamify">ws-streamify</a></h2><p>The first thing I realized is that the back-pressure is already implemented in Node.js streams and there&#39;s no need to implement the wheel. All we need is to extend them and correctly tune the connection between sockets. Then I checked out existing implementations and found out that they don&#39;t support back-pressure. So I needed to make it myself. Initially I implemented the same approach as in <code>docker-exec-websocket-server</code> with <code>pause</code> and <code>resume</code> codes and wrote tests for it. Everything looked pretty well until I decided to pipe a stream to it and check network profiling in Chrome DevTools :) It turned out that this approach is not reliable. When stream that is being piped is too fast it manages to send enormous amounts of data before it receives a message from the consumer that asks to stop sending data. The buffers are being terribly overflowed constantly. By the way, I couldn&#39;t find any tests for handling back-pressure in the <code>docker-exec-websocket-server</code> sources. So, I thought that a better idea would be to implement a similar to TCP approach — explicit acknowledgement of whether the other side can send the next message or not. It <em>might</em> be a little overhead <strong>but it&#39;s reliable</strong>. I&#39;ve tested it and it works much better, the buffers are filling up in acceptable levels. Performance is also very fine, but if it&#39;s not enough you can simply increase the chunks size. The library is already on npm, have tests and CI is configured.</p>
<h2>Final</h2><p>In the upcoming week I want to make a server using <code>ws-streamify</code> and docker containers (in order to make it more native with taskcluster environment). I&#39;ve already familirar with using docker API from javascript (btw, I managed to get rid of that hack with <code>sleep</code> in tests!). Also, I want to finish GDB wrapper (well, almost finish :)).</p>
<h2>P.S.</h2><ul>
<li>Seems like I broke RSS the last time... Sorry, it&#39;s fixed now :)</li>
<li>Since I decided to use a different protocol for <code>react-gdb</code> I don&#39;t need <code>ws-exec</code> anymore and I decided to delete it. Anyway, with <code>ws-streamify</code> it can be implemented very easily. </li>
<li>I hate exams (ﾉಥДಥ)ﾉ︵┻━┻</li>
</ul>
]]></description>
        <pubDate>Mon Jun 06 2016 00:00:00 GMT+0300 (MSK)</pubDate>
        <link>http://baygeldin.name/gsoc-2016/rethinking</link>
        <guid isPermaLink="true">http://baygeldin.name/gsoc-2016/rethinking</guid>
      </item>
    
    
      <item>
        <title>First week</title>
        <description><![CDATA[<p>So, the first week of GSoC has passed and here&#39;s my first weekly report. During this week the main goal was to get some <code>gdb-js</code> tests running. So, I&#39;ve implemented some tests first and then started to raise functionality to match these tests. But as usual things have been changing along the way. </p>
<h2>On tests</h2><p>The first idea was to write tests this way: </p>
<ol>
<li>Mock the stdin/stdout/stderr streams</li>
<li>Pass them to the newly created GDB wrapper instance</li>
<li>Check the state consistency and the stdin output</li>
</ol>
<p>For streams mocking I decided to create a command line util to run GDB and write the results of its execution to a json file (with streams splitting, of course). The problem here was that output of some programs when they are not attached to interactive device is line-buffered and debugging these programs becomes hard. The workaround I&#39;ve come up with:</p>
<pre><code class="language-javascript">let gdb = spawn(&#39;stdbuf&#39;, [&#39;-i0&#39;, &#39;-o0&#39;, &#39;-e0&#39;,
  &#39;gdb&#39;, &#39;--interpreter=mi&#39;, &#39;./main&#39;])
</code></pre>
<p>So far so good and it feels like it&#39;s a right approach to do unit tests. But there is one significant disadvantage to it: the tests are not clear. It&#39;s hard to reason about what the specific test should do by looking at the json file with recorded streams. So, I decided to take another approach — use the actual GDB instance. So the tests now are looking more like integration tests than unit tests. But it&#39;s fine... The only thing I don&#39;t like is that they&#39;re much slower for obvious reasons :) The integration tests are done this way:</p>
<ul>
<li>I&#39;ve set up a <a href="https://github.com/baygeldin/gdb-examples">GitHub repo</a> with Docker image and an <a href="https://hub.docker.com/r/baygeldin/gdb-examples/">automation build for it</a> on DockerHub.</li>
<li>I use <code>dockerode-promise</code> wrapper to run the Docker container with this image from Node.js</li>
<li>And then execute tests within the container</li>
</ul>
<p>The next challenge was to write the code that would match these tests. First, I created some abstract implementation of the GDB wrapper class. I choosed to use <code>highland.js</code> for stream handling since it has zero dependencies and awesome documentation. Then I started to think about parser.</p>
<h2>On parsers</h2><p>GDB/MI output syntax plays well with JSON in fact. So the natural approach was to map it to JSON. I&#39;ve considered several parser generators and decided to use <code>PEG.js</code> since it&#39;s very easy to use and it has a nice <a href="http://pegjs.org/online">online version</a>. There was one problem with symbols escaping in the grammar but I&#39;ve handled it by taking an example of JSON parser for PEG.js:</p>
<pre><code class="language-javascript">Const &quot;c-string&quot;
  = &quot;\&quot;&quot; chars:Char* &quot;\&quot;&quot; { return chars.join(&#39;&#39;) }

Char &quot;char&quot;
  = [\x20-\x21\x23-\x5B\x5D-\u10FFFF]
  / &quot;\\&quot; seq:Escaped { return seq }

Escaped &quot;escaped&quot;
  = (&quot;\&quot;&quot; / &quot;\\&quot;) / (&quot;b&quot; / &quot;f&quot; / &quot;n&quot; / &quot;r&quot; / &quot;t&quot;) {
      return &#39;\\&#39; + text()
    }
</code></pre>
<p>By the way, seems like the official GDB/MI syntax has some mistakes according to their bugzilla but I hope it won&#39;t be a big problem.</p>
<h2>Results</h2><ul>
<li>Parser for GDB/MI is working</li>
<li>Test for state checking is passing</li>
</ul>
<h2>P.S.</h2><ul>
<li>During my parser generators investigation I&#39;ve understood that my knowledge of syntax analysers is poor... So I planned to spend some time on them later on. On the other hand, I found an awesome and almost fresh article about <a href="http://www.antlr.org/papers/allstar-techreport.pdf">state-of-art analyzer</a>!</li>
<li>The next week I want to write even more tests and more methods for a GDB wrapper. I need to do it in pace in order to save some time for preparation to the exam which will be held on 9th of June.</li>
</ul>
]]></description>
        <pubDate>Mon May 30 2016 00:00:00 GMT+0300 (MSK)</pubDate>
        <link>http://baygeldin.name/gsoc-2016/first-week</link>
        <guid isPermaLink="true">http://baygeldin.name/gsoc-2016/first-week</guid>
      </item>
    
    
      <item>
        <title>Hello World!</title>
        <description><![CDATA[<p>Hi! Since this is the first post, let me introduce myself. My name is Alexander Baygeldin, I&#39;m a student of the Saint-Petersburg State University and this summer I&#39;ll work on the web GDB frontend project for Mozilla as part of Google Summer of Code 2016. In this blog I will publish my weekly reports (it&#39;s the requirement of the project). By the way, English is not my native language, so sorry in advance for mistakes and typos. Anyway, I hope I&#39;ll be able to explain everything understandable. So, let&#39;s start! :)  </p>
<p>In this project the goal is to provide a GUI for GDB in the browser so that other developers can use it to easily and intuitively debug projects running in a cloud environment. You can read more about it on the <a href="about">about page</a>. Here I&#39;ll focus on the architectural design of the project and some things and investigations that I&#39;ve done during community bonding period.  </p>
<h2>Project Proposal</h2><blockquote>
<p><strong>Disclaimer:</strong> this is the dense retelling of the project proposal, so feel free to skip it if you&#39;re already familiar with it.</p>
</blockquote>
<p>Basically, this project is a Single Page Application which, when given a link to the WebSockets server, provides a web-interface to interact with GDB by processing stdin/stdout/stderr streams from it. It’s just a static page and all it needs to work is a link to the WebSocket server which can be implemented quickly in any language (Go, JavaScript, Ruby, etc.). So, react-gdb is server
agnostic and can even be run on the GitHub pages :) Conceptually, I see the GUI like this:  </p>
<p><img src="http://baygeldin.name/gsoc-2016/assets/images/wireframe.png" alt="Wireframe">   </p>
<p>The framework of choice for this project is React/Redux. This is the perfect choice for this kind of project since the GUI can be very well represented as a function of GDB state. However, it’s better to keep the logic for GDB streams processing outside of React application to maintain a good separation of concerns and make sure our application knows as little as possible about GDB. It’s possible by creating a GDB abstraction. I see the project architecture like this:  </p>
<p><img src="http://baygeldin.name/gsoc-2016/assets/images/architecture.png" alt="Architecture">   </p>
<p>The abstraction should accept actions, process them, and forward them to the server. And it should also maintain its state (i.e. current file, current line of code, backtrace, locals, etc.) and notify our application every time it changes. This will lead to the
painless synchronization with the actual state of GDB. So, the react application will concern only about how things look and will maintain an UI state within it, while GDB abstraction will maintain the state of GDB and will know how to work with it. This will let me to implement the parts of the project step-by-step, independently and will allow to easily test everything thanks to loose coupling.</p>
<h2>Investigations</h2><p>During community bonding period I&#39;ve set up an initial environment and made myself familiar with <code>docker-exec-websocket-server</code> so that when the coding period starts I&#39;ll start actually coding. In this section I&#39;ll try to reveal more detail about it.  </p>
<p>The project actually contains three abstractions: thing for piping process streams through WebSockets, GDB abstraction and finally a web application (UI). Since the first two abstraction can be useful outside of the project I decided to make separate repositories for them. It also will allow me to develop and test them independently. So, in the end I expect to have three separate npm packages. The client side app will have first two packages as dependencies. However, it absolutely won&#39;t affect the ease of development and I won&#39;t have to update npm packages everytime I change something in the dependencies, because I use git submodules together with <code>npm link</code>. With this approach I can develop separate npm packages simultaneously and once any of them become solid I can easily get rid of the related git submodule and require it as a typical npm dependency (it will require no changes to the code). Okay, so let&#39;s move to the abstractions.</p>
<h3><a href="https://github.com/baygeldin/ws-exec">ws-exec</a></h3><p>When I was playing with <code>docker-exec-websocket-server</code> I found out that it&#39;s not optimised for browser use and it&#39;s not working out-of-the-box without some tweaking. I considered making a PR, but decided to create a separate repo. The main reason for this is that I wanted to make the debugger able to use with local projects, and having a dependency for Docker is not a good user experience. So, the main idea was to generalize the <code>docker-exec-websocket-server</code>. The good news is that protocol it uses is very common (not docker specific) so it&#39;s actually easy to keep <code>ws-exec</code> compatible with <code>docker-exec-websocket-server</code>. In fact, it should be possible to rewrite <code>docker-exec-websocket-server</code> using <code>ws-exec</code> (I kept that in mind when I was writing <code>ws-exec</code>), but first it needs some (maybe lot) refactoring and tests. So, I&#39;ll leave it for later since client side part of <code>ws-exec</code> is already working well with server side part of <code>docker-exec-websocket-server</code>. Also, when I was studying the sources of <code>docker-exec-websocket-server</code> I understood how back-pressure is implemented there and why it&#39;s necessary. </p>
<h3><a href="https://github.com/baygeldin/gdb-js">gdb-js</a></h3><p>The second abstraction is GDB/MI wrapper. It accepts process streams (e.g. produced by <code>ws-exec</code>) and provides a handy interface to GDB. There are such wrappers already, however none of them suit this project. The first drawback of them is that they do not accept streams and hence not usable in the browser environment. The second drawback (and the main one) is that they do not maintain a consistent state of GDB. In this project we <em>need</em> to have state of GDB since after every action the current file, current line of code, call stack, locals, globals and many other things can change. Handling all of these in the client-side app is error-prone and just a bad separation of concerns. So, the GDB wrapper should maintain the state itself and provide handy events for notifying the application on every state change. With such wrapper writing the UI will be <strong>much</strong> easier. So, as stated in my timeline, I will focus on this part of the project for a while. And I&#39;ll start with writing tests. This is a perfect project for practicing BDD :)</p>
<h3><a href="https://github.com/baygeldin/react-gdb">react-gdb</a></h3><p>Finally, we&#39;re here :) It&#39;s the main goal of this project — the GUI. It&#39;s specific for GDB and relies on the protocol <code>ws-exec</code> uses, but one of the core ideas is that these parts should be easily swappable. And it&#39;s definitely possible since <code>gdb-js</code> and <code>ws-exec</code> are decoupled from the application itself. Basically, <code>react-gdb</code> is just a static site, but for convenience it&#39;ll be also published on npm (without dependencies since it&#39;s just a static assets). At this stage of the project there&#39;s no React/Redux here. I&#39;ll start to use them once <code>gdb-js</code> starts to become solid. However, the environment for this is ready: the demo server that runs docker container, docker image and configured webpack. Here&#39;s a quick example of how <code>ws-exec</code> and demo server are glued together within <code>react-gdb</code>: </p>
<p><img src="http://baygeldin.name/gsoc-2016/assets/images/example_console.png" alt="Example">   </p>
<p>Also, I was experimenting with using webpack for bundling npm packages and backend, but understood that it wasn&#39;t a good idea :P Webpack wasn&#39;t designed for this type of things. That being said, I had experience with webpack before, but I think that I finally got the philosophy behind it only recently. Here&#39;re some things that I&#39;ve understood:</p>
<ul>
<li>npm is not made for minified and bundled versions! It&#39;s conceptually wrong to publish such packages. CDN is for minified versions.</li>
<li>The developer himself should worry about the final bundle size, not the package maintainer. Hopefully, it&#39;s done very easily with <code>IgnorePlugin</code>, <code>ContextReplacementPlugin</code>, <code>null-loader</code> and <code>display-all-modules</code> option. However, the package maintainer should denote which dependencies can be turned off without affecting his package (individually for browser environment, node environment, production mode and debug mode).</li>
</ul>
<h2>P.S.</h2><p>I decided to write things that are not strictly related to the project, but related to the GSoC, in the postscriptum section. And here&#39;re some of these things:  </p>
<ul>
<li>WHY there&#39;re so much fish in the header of the blog? Well, it&#39;s because the official mascot of GDB is a fish (archerfish to be precise). But I couldn&#39;t find a good picture with archerfish, so I decided to leave this one (it&#39;s pretty nice, isn&#39;t it? :)) </li>
</ul>
<blockquote>
<p>For a fish, the archerfish is known to shoot down bugs from low hanging plants by spitting water at them.</p>
</blockquote>
<ul>
<li>This blog is powered by harp (a static site server with built-in pre-processing). It&#39;s not a static-blog engine but it turned out that it&#39;s very handy for this and it&#39;s also very flexible. I encourage everyone to give it a try!</li>
<li>This and the next months (May and June) are very busy due to the exams, but I took it into account when I was planning my timeline. Actually I feel optimistic about this project and I believe I will finish the <code>gdb-js</code> before midterm and start doing the UI. So, let&#39;s start! :)</li>
</ul>
<pre><code class="language-javascript">console.log(&#39;Hello World!&#39;)
</code></pre>
]]></description>
        <pubDate>Wed May 18 2016 00:00:00 GMT+0300 (MSK)</pubDate>
        <link>http://baygeldin.name/gsoc-2016/hello-world</link>
        <guid isPermaLink="true">http://baygeldin.name/gsoc-2016/hello-world</guid>
      </item>
    
  </channel>
</rss>
